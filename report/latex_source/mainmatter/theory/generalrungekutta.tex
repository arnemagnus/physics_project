\subsection{The Runge-Kutta family of numerical ODE solvers}
\label{sub:the_runge_kutta_family_of_numerical_methods}

In numerical analysis, the Runge-Kutta family of methods is a popular
collection of implicit and explicit iterative methods, used in temporal
discretization in order to obtain numerical approximations of the \emph{true}
solutions of systems like \eqref{eq:ivpsystem}. The German mathematicians C.
Runge and M. W. Kutta developed the first of the family's methods at the turn
of the twentieth century \parencite[p.134]{hairer1993solving}. The general
scheme of what is now known as a Runge-Kutta method is as follows: \\

\begin{defn}
    \label{def:generalrungekutta}
    Let $s$ be an integer and $a_{1,1},a_{1,2},\ldots,a_{1,s},a_{2,1},
    a_{2,2},\ldots,a_{2,s},\ldots,a_{s,1},a_{s,2},\ldots,a_{s,s}$,
    $b_{1},b_{2},\ldots,b_{s}$ and $c_{1},c_{2},\ldots,c_{s}$ be real
    coefficients. Let $h$ be the numerical step length used in the
    temporal discretization. Then, the method
\begin{equation}
    \label{eq:generalrungekutta}
    \begin{aligned}
        k_{i} &= f\bigg(t_{n}+c_{i}h,x_{n}+
                h\sum\limits_{j=1}^{s}a_{i,j}k_{j}\bigg),\quad{}i=1,\ldots,s\\
        x_{n+1} &= x_{n} + h\sum\limits_{i=1}^{s}b_{i}k_{i}
    \end{aligned}
\end{equation}
is called an \emph{s-stage Runge-Kutta method} for the system
\eqref{eq:ivpsystem}.
\end{defn}

The main reason to include multiple stages in a Runge-Kutta method,
is to improve the numerical accuracy of the computed solutions.
The \emph{order} of a Runge-Kutta method can be defined as follows:\\

\begin{defn}
    \label{def:rungekuttaorder}
    A Runge-Kutta method, given by~\cref{eq:generalrungekutta}, is
    said to be of \emph{order} $p$ if, for sufficiently smooth systems
    \eqref{eq:ivpsystem}, the local error $e_{n}$ scales as $h^{p+1}$, that is:
    \begin{equation}
        \label{eq:rungekuttaorder}
        e_{n}=\norm{x_{n}-u_{n-1}(t_{n})} \leq Kh^{p+1},
    \end{equation}
    where $u_{n-1}(t)$ is the exact solution of the ODE in system
    \eqref{eq:ivpsystem} at time $t$, subject to the initial condition
    $u_{n-1}(t_{n-1})=x_{n-1}$, and $K$ is a numerical constant. This is true,
    if the Taylor series for the exact solution $u_{n-1}(t_{n})$ and the
    numerical solution $x_{n}$ coincide up to (and including) the term $h^p$.
\end{defn}

The \emph{global} error
\begin{equation}
    \label{eq:rungekuttaglobalorderdef}
    E_{n} = x_{n}-x(t_{n}),
\end{equation}
where $x(t)$ is the exact solution of system~\eqref{eq:ivpsystem} at time $t$,
accumulated by $n$ repeated applications of the numerical method, can be
estimated by
\begin{equation}
    \label{eq:rungekuttaglobalorderapprox}
    \abs{E_{n}} \leq C\sum\limits_{l=1}^{n}\abs{e_{l}},
\end{equation}
where $C$ is a numerical constant, depending on both the right hand side of
the ODE in system~\eqref{eq:ivpsystem} and the difference $t_{n}-t_{0}$.
Making use of~\cref{def:rungekuttaorder}, the global error can be estimated
by
\begin{gather}
    \label{eq:rungekuttaglobalorderestimate}
    \begin{aligned}
        \abs{E_{n}}&\leq C\sum\limits_{l=1}^{n}\abs{e_{l}} %
        \leq C\sum\limits_{l=1}^{n}\abs{K_{l}}\hspace{0.5ex}h^{p+1} \\
        &\leq C\hspace{0.5ex}\max\limits_{l}\big\{\abs{K_{l}}\big\}\hspace{0.5ex}n\hspace{0.5ex}h^{p+1}%
        \leq C\hspace{0.5ex}\max\limits_{l}\big\{\abs{K_{l}}\big\}\hspace{0.5ex}\frac{t_{n}-t_{0}}{h}\hspace{0.5ex}h^{p+1}\\
        &\leq \widetilde{K}h^{p},
    \end{aligned}
\end{gather}
where $\widetilde{K}$ is a numerical constant.
\Cref{eq:rungekuttaglobalorderestimate} demonstrates that, for a $p$-th
order Runge-Kutta method, the global error can be expected to scale
as $h^{p}$.

%It is easy to show that if the local error of a Runge-Kutta method is of order
%$p+1$, the global error, i.e., the total accumulated error resulting of
%applying the algorithm a number of times, is expected to scale as $h^{p}$.
%Showing this is left as an exercise for the interested reader.
%
In definition~\ref{def:generalrungekutta}, the matrix $(a_{i,j})$ is commonly
called the \emph{Runge-Kutta matrix}, while $b_{i}$ and $c_{i}$ are known as
the \emph{weights} and \emph{nodes}, respectively.  Since the 1960s, it has
been customary to represent Runge-Kutta methods, given by
\cref{eq:generalrungekutta}, symbolically, by means of mnemonic devices known
as Butcher tableaus \parencite[p.134]{hairer1993solving}. The Butcher tableau
for a general \emph{s}-stage Runge-Kutta method, introduced in definition
\ref{def:generalrungekutta}, is presented in table~\ref{tab:generalbutcher}.

\clearpage

\begin{table}[htpb]
    \centering
    \caption[Butcher tableau representation of a general $s$-stage
                Runge-Kutta method]{Butcher tableau representation of a general
                    $s$-stage Runge-Kutta method.}
    \label{tab:generalbutcher}
    \[\renewcommand{\arraystretch}{1.25}
        \begin{array}{c|cccc}
            \toprule
            c_{1} & a_{1,1} & a_{1,2} & \ldots & a_{1,s}\\
            c_{2} & a_{2,1} & a_{2,2} & \ldots & a_{2,s}\\
            \vdots & \vdots & \vdots & \ddots & \vdots \\
            c_{s} & a_{s,1} & a_{s,2} & \ldots & a_{s,s}\\
            \hline
            & b_{1} & b_{2} & \ldots & b_{s}\\
            \bottomrule
    \end{array}
\]
\end{table}

For explicit Runge-Kutta methods, the Runge-Kutta matrix $(a_{i,j})$ is lower
triangular. Similarly, for fully implicit Runge-Kutta methods, the Runge-Kutta
matrix is upper triangular. The difference between explicit and implicit
methods is outlined in~\cref{eq:exim}.
%Unlike explicit methods, implicit methods require
%the solution of a linear system at every time level, making them more
%computationally demanding than their explicit siblings. The main selling point
%of implicit methods is that they are more numerically stable than explicit
%methods. This property means that implicit methods are particularly well-suited
%for \emph{stiff} systems, i.e., physical systems with highly disparate time
%scales~\parencite[p.2]{hairer1996solving}. For such systems,
%most explicit methods are highly numerically unstable, unless the numerical step
%size is made exceptionally small, rendering most explicit methods practically
%useless. For \emph{nonstiff} systems, however, implicit methods behave similarly
%to their explicit analogues in terms of numerical accuracy and
%convergence properties.
%
%\clearpage

During the first half of the twentieth century, a substantial amount of research
was conducted in order to develop numerically robust, high-order, explicit
Runge-Kutta methods. The idea was that using such methods would mean one could
resort to larger time increments $h$ without sacrificing precision in the
computational solution. However, the number of stages $s$ grows quicker than
linearly as a function of the required order $p$. It has been proven
that, for $p\geq5$, no explicit Runge-Kutta method of order $p$ with $s=p$
stages exists \parencite[p.173]{hairer1993solving}. This is
one of the reasons for the attention shift from the latter half of the 1950s
and onwards, towards so-called \emph{embedded} Runge-Kutta methods.

The basic idea of embedded Runge-Kutta methods is that they, aside from the
numerical approximation $x_{n+1}$, yield a second approximation
$\widehat{x}_{n+1}$. The difference between the two approximations then yields
an estimate of the local error of the less precise result, which can be used for
automatic step size control~\parencite[pp.167--168]{hairer1993solving}. The
trick is to construct two independent, explicit Runge-Kutta methods which both
use the \emph{same} function evaluations. This results in practically obtaining
the two solutions for the price of one, in terms of computational complexity.
The Butcher tableau of an embedded, general, explicit Runge-Kutta method is
illustrated in~\cref{tab:generalembeddedbutcher}.

\begin{table}[htpb]
    \centering
    \caption[Butcher tableau representation of general, embedded, explicit
    Runge-Kutta methods]{Butcher tableau representation of general, embedded,
        explicit Runge-Kutta methods.}
    \label{tab:generalembeddedbutcher}
    \[\renewcommand{\arraystretch}{1.25}
    \begin{array}{c|ccccc}
    \toprule
    0 \\
    c_{2} & a_{2,1} \\
    c_{3} & a_{3,1} & a_{3,2} \\
    \vdots & \vdots & \vdots & \ddots\\
    c_{s} & a_{s,1} & a_{s,2} & \ldots & a_{s,s-1}\\
    \hline
    & b_{1} & b_{2} & \ldots & b_{s-1} & b_{s} \\
    \hline
    & \widehat{b}_{1} & \widehat{b}_{2} & \ldots & \widehat{b}_{s-1}& \widehat{b}_{s}\\
    \bottomrule
    \end{array}
\]
\end{table}

For embedded methods, the coefficients are tuned such that
\begin{subequations}
    \begin{equation}
        \label{eq:embeddedsol}
        x_{n+1} = x_{n} + h\sum\limits_{i=1}^{s}b_{i}k_{i}
    \end{equation}
is of order $p$, and
    \begin{equation}
        \label{eq:embeddedinterp}
        \widehat{x}_{n+1} = x_{n} + h\sum\limits_{i=1}^{s}\widehat{b}_{i}k_{i}
    \end{equation}
\end{subequations}
is of order $\widehat{p}$, typically with $\widehat{p} = p \pm 1$. Which
of the solutions are used to continue the numerical integration, depends on
the integration scheme in question. In the following, the solution which is
\emph{not} used to continue the integration, will be referred to as the
\emph{interpolant} solution.

%\clearpage
\subsection{The Runge-Kutta methods under consideration}
\label{sub:the_runge_kutta_methods_under_consideration}

There exists an abundance of Runge-Kutta methods. Many of them are
fine-tuned for specific constraints, such as problems of varying degrees of
stiffness. It is neither possible nor meaningful to investigate them all
in the context of general flow dynamics. For this reason, we consider two classes
of explicit Runge-Kutta methods, namely singlestep and adaptive stepsize
methods. From both classes, we include four different general-purpose ODE solvers
of varying order.

\subsubsection{Singlestep methods}
\label{ssub:singlestep_methods}

The singlestep methods under consideration are the classical, explicit
Runge-Kutta methods of orders one through to four, i.e., the \emph{Euler},
\emph{Heun}, \emph{Kutta} and \emph{classical Runge-Kutta} methods. The
Euler method is \nth{1}-order accurate, and requires a single function
evaluation of the right hand side of the ODE of system
\eqref{eq:ivpsystem} or~\eqref{eq:ivpsystemhigherdimensions} at each time step.
Its Butcher tableau representation can be found in~\cref{tab:butchereuler}.
It is the simplest explicit method for numerical integration of ordinary
differential equations. The Euler method is often used as a basis to construct
more complex methods, such as the Heun method, which is also known as the
\emph{improved Euler method} or the \emph{explicit trapezoidal rule}. The Heun
method is \nth{2}-order accurate, and requires two function evaluations at each
time step. Its Butcher tableau representation can be found in
\cref{tab:butcherrk2}.

\input{mainmatter/theory/butchertableaus/euler.tex}
\clearpage
\input{mainmatter/theory/butchertableaus/rk2.tex}

The Kutta method is \nth{3}-order accurate, and requires three function
evaluations of the right hand side of the ordinary differential
\cref{eq:ivpsystem} or ~\eqref{eq:ivpsystemhigherdimensions} at each time
step. Its Butcher tableau representation can be found in \cref{tab:butcherrk3}.
The classical Runge-Kutta method is \nth{4}-order accurate, and perhaps the most
well-known and frequently used of the four singlestep schemes discussed in this
project. One reason for its popularity is that it is exceptionally stable
numerically (of the aforementioned singlestep methods, the classical
Runge-Kutta method has the largest numerical stability domain). Another is that,
as mentioned previously, for $p\geq5$, no explicit Runge-Kutta method of order
$p$ with $s=p$ stages exist
\parencite[p.173]{hairer1993solving} -- in other words,
the required number of function evaluations grows at a disproportional rate with
the required accuracy order. For systems with right hand sides which are
computationally costly to evaluate, this means that one frequently is able to
obtain the desired numerical accuracy more effectively by using, for instance,
the classical Runge-Kutta method with a finer step length. The Butcher tableau
representation of the classical Runge-Kutta method can be found in
\cref{tab:butcherrk4}.

\input{mainmatter/theory/butchertableaus/rk3.tex}
\clearpage
\input{mainmatter/theory/butchertableaus/rk4.tex}

\subsubsection{Adaptive stepsize methods}
\label{ssub:adaptive_stepsize_methods}

The adaptive stepsize methods under consideration are the Bogacki-Shampine
3(2) and 5(4) methods, and the Dormand-Prince 5(4) and 8(7) methods. The digit
outside of the parentheses indicates the order of the solution which is used
to continue the integration, while the digit within the parentheses indicates
the order of the interpolant solution. Note that the concept of \emph{order}
does not translate directly from singlestep methods, as a direct consequence
of the adaptive time step. Although the \emph{local} errors of each integration
step scale as per~\cref{eq:rungekuttaorder}, the bound on the \emph{global}
(i.e., observable) error suggested in~\cref{eq:rungekuttaglobalorderestimate}
is invalid, as the time step is, in principle, different for each integration
step. Generally, lower order methods are more suitable than higher order methods
for cases where crude approximations of the solution are sufficient.
\citeauthor{bogacki1989pair} argue that their methods
outperform other methods of the same order
\parencite{bogacki1989pair,bogacki1996efficient}, a notion which, for the 5(4)
method, is supported by
\textcite[p.194]{hairer1993solving}.

Butcher tableau representations of the aforementioned adaptive stepsize methods
can be found in
\cref{tab:butcherbs32,tab:butcherbs54,tab:butcherdopri54,tab:butcherdopri87},
the latter of which has been typeset in landscape orientation for the reader's
convenience. Three of the methods, namely the Bogacki-Shampine 3(2) and 5(4)
methods, in addition to the Dormand-Prince 5(4) method, possess the so-called
\emph{First Same As Last} property. This means that the last function evaluation
of an accepted step is exactly the same as the first function evaluation of the
next step. The notions of accepted and rejected integration steps will be
elaborated upon in
\cref{sub:on_the_implementation_of_embedded_runge_kutta_methods}. The
\emph{First Same As Last} property is readily apparent from their Butcher
tableaus, where the $b$ coefficients correspond exactly with the last row of the
Runge-Kutta matrix. This property reduces the computational cost of a successive
step. Moreover, the Bogacki-Shampine 5(4) method yields \emph{two} interpolant
solutions. The details on how these were used, will be presented in
\cref{sub:on_the_implementation_of_embedded_runge_kutta_methods}.
%\clearpage
\input{mainmatter/theory/butchertableaus/bs32.tex}

%\clearpage
\input{mainmatter/theory/butchertableaus/bs54.tex}

%\clearpage
\input{mainmatter/theory/butchertableaus/dp54.tex}

%\clearpage
\input{mainmatter/theory/butchertableaus/dp87.tex}

\clearpage

