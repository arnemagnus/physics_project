\section{Advecting a set of initial conditions}
\label{sec:advecting_a_set_of_initial_conditions}

The variational model is based upon the advection of non-interacting tracers,
which is described in \cref{sec:typeofflow}, by the velocity field defined in
equation \eqref{eq:doublegyre}. The system has no known analytical solution for
the tracer trajectories. Thus, it must be solved numerically, by means of some
numerical integration method, e.g.\ a Runge-Kutta method, some of which are
outlined in~\cref{sub:the_runge_kutta_family_of_numerical_methods}. With the
main focus of this project being the dependence on LCSs on the chosen
integration method, the advection was performed using all of the numerical
integrators introduced in
\cref{sub:the_runge_kutta_methods_under_consideration}.

\subsection{Generating a set of initial conditions}
\label{sub:generating_a_set_of_initial_conditions}
The computational domain $\mathcal{U}=[0\hspace{1ex}2]\times[0\hspace{1ex}1]$
was discretized by a set of linearly spaced tracers, with $1000\times500$ grid
points, effectively creating a nearly uniform grid of approximate spacing
$\Delta{x}\simeq\Delta{y}\simeq0.002$. Tracers were placed on and within the
domain boundaries of $\mathcal{U}$. The grid was extended artificially,
with an additional two rows or columns appended to all of the domain edges,
with the same grid spacing as the \emph{main} grid. This was done in order to
ensure that the dynamics at the domain boundaries were included in the analysis
to follow. The extended grid thus had a total of $1004\times504$ grid points.
The construction of the grid is illustrated in figure~\ref{fig:initialgrid}.

\vspace{\fill}
\input{mainmatter/method/figures/initialgridfigure.tex}


In order to increase the resolution of the Cauchy-Green strain tensor,
it is necessary to increase the accuracy with which one computes the
Jacobian of the flow map, as can be seen from equation \eqref{eq:cauchygreen}.
This was done by advecting a set of auxiliary tracer points surrounding each
main point. To each tracer point $\vct{x}_{i,j}=(x_{i},y_{j})$, neighboring
points defined as

\begin{equation}
    \label{eq:auxgrid}
    \begin{gathered}
        \vct{x}_{i,j}^{r} = (x_{i}+\delta{x},y_{j}),%
                \quad\vct{x}_{i,j}^{l} = (x_{i}-\delta{x},y_{j})\\
                \vct{x}_{i,j}^{u} = (x_{i},y_{j}+\delta{y}),%
                \quad\vct{x}_{i,j}^{l} = (x_{i},y_{j}-\delta{y})\\
\end{gathered}
\end{equation}

were assigned, where $\delta{x}$ and $\delta{y}$ are increments smaller than
the grid spacings $\Delta{x}\simeq\Delta{y}$. Even though this effectively means
that five times as many tracers have to be advected, the resulting accuracy in
computing the Jacobian of the flow map, by means of the auxiliary tracers, is
determined by the independent variables $\delta{x}$ and $\delta{y}$. This, in
principle, allows for much higher precision than what would be obtained by
simply advecting five times as many \emph{equidistant} tracers. The concept
of the auxiliary tracers is illustrated in figure~\ref{fig:auxiliarygrid}.

\input{mainmatter/method/figures/auxiliarygridfigure.tex}

Because of the limited number of decimal digits which can be accuractely
represented by floating-point numbers, however, there is a strict lower limit
to which it makes sense to lower the values of $\delta{x}$ and $\delta{y}$. In
particular, the smallest number which can be resolved as a double-precision
floating-point number is of the order $10^{-16}$. When decreasing the
auxiliary grid spacing, the increase in precision is quickly offset by the fact
that one automatically gets allocated a smaller number of decimal digits with
which one calculate the discrete approximation of the derivatives involved
in the Jacobian. This is due to the double gyre velocity field, being
reasonably well-behaved, leading most tracers which are initially close to
follow very similar trajectories, often ending up with a separation distance
comparable to the initial offset. For this reason, the auxiliary grid spacing
$\delta{x}=\delta{y}=10^{-5}$ was chosen --- three orders of magnitude smaller
than the original grid spacing, ensuring that the derivatives in the Jacobian
are far more well-resolved than for the main tracers, while also leaving
approximately $10$ decimal digits for which there can be a difference in the
final positions of the auxiliary tracers.

\subsection{On the choice of numerical step lengths and tolerance levels}
\label{sub:on_the_choice_of_numerical_step_lengths_and_tolerance_levels}

For the fixed stepsize integrators, step lengths of $10^{-1}$ through to
$10^{-5}$ were used. The reason even smaller step lengths were not considered
is the following: For a step length of $10^{-5}$, the total number of
integration steps required in order to take the system from $t=0$ to $t=20$
is of order $10^{6}$. As previously mentioned, the inherent accuracy of
double-precision floating point numbers is of order $10^{-16}$. Thus, the
total floating point error expected to arise when integrating with a step
length of $10^{-5}$ is of order $10^{-10}$.

The least accurate of the fixed stepsize integrators integrators under
consideration, the Euler method, is presented in \cref{tab:butchereuler}. It is
\nth{1} order accurate globally, meaning that its local error is of \nth{2}
order, per \cref{def:rungekuttaorder}. Thus, we expect that the local error of
the Euler method, for a step length of $10^{-5}$, is of order $10^{-10}$, that
is, the same order as the accumulated floating-point errors. Reducing the time
step further necessarily leads to an increase in the accumulated floating-point
errors, meaning that we cannot reasonably expect to resolve the positions
from one step to the next more accurately, for the Euler method. At the very
least, a time step of $10^{-5}$ appears to represent a point after which
there is little to be gained in terms of increased numerical accuracy for the
Euler method. For the other fixed stepsize integrators, which are of higher
order, we expect this breaking point to occur for a somewhat larger time step.

While the above logic does not translate directly for the adaptive stepsize
integrators, empirical tests indicate that for both of the Bogacki-Shampine
integrators, as well as for the Dormand-Prince 5(4) integrator, the accumulated
floating-point errors caught up to the required tolerance level at some point
between the levels $10^{-10}$ and $10^{-11}$, while the Dormand-Prince 8(7)
integrator held its ground until a tolerance level of about $10^{-13}$. For this
reason, tolerance levels of $10^{-1}$ through to $10^{-10}$ were used for the
adaptive stepsize integrators. Furthermore, as no analytical solution exists
for the double gyre system, a numerical solution is needed as the reference.
Following the discussion above, the solution obtained via the Dormand-Prince
8(7) integrator with a numerical tolerance level of $10^{-12}$ was used for
this purpose.

With the addition of the aforementioned auxiliary tracers, the total number
of tracers which were advected became of order $2.5$ million. In order to
accelerate the computational process, the advection was parallellized by means
of MPI and ran on NTNU's supercomputer, Vilje. The associated speedup was
crucial for this project --- for example, advection using the Euler method
and a time step of $10^{-5}$ required in excess of $1000$ computational
walltime hours; an insurmountable feat for most computers, including the
author's own personal laptop.

\subsection{On the implementation of embedded Runge-Kutta methods}
\label{sub:on_the_implementation_of_embedded_runge_kutta_methods}

In order to implement automatic step size control, the procedure suggested
by \textcite[pp.167--168]{hairer1993solving} was followed
closely. A starting step size of $h=0.1$ was used throughout. For the first
solution step, the embedded integration method, as described in
\cref{sub:the_runge_kutta_family_of_numerical_methods} yields the two
approximations $x_{1}$ and $\widehat{x}_{1}$, from which the difference
$x_{1}-\widehat{x}_{1}$ can be used as an estimate of the error of the less
precise result. The idea is to enforce the error of the numerical solution to
satisfy componentwise:

\begin{equation}
    \label{eq:embeddederror}
    \abs{x_{1,i}-\widehat{x}_{1,i}} \leq \scem_{i},\quad{}%
    \scem_{i}=\atol_{i}+\max\big(\abs{x_{0,i}},\abs{x_{1,i}}\big)\cdot{}\rtol_{i}
\end{equation}

where $\atol_{i}$ and $\rtol_{i}$ are the desired numerical tolerances, prescribed
by the user. For this project, $\atol_{i}$ was always set equal to $\rtol_{i}$.

As a measure of the numerical error,

\begin{equation}
    \label{eq:embeddednumericalerror}
    \errem = \sqrt{\frac{1}{n}\sum\limits_{i=1}^{n}%
    {\bigg(\frac{x_{1,i}-\widehat{x}_{1,i}}{\scem_{i}}\bigg)}^{2}}
\end{equation}

is used. Then, $\errem$ is compared to $1$ in order to find an optimal step
size. From~\cref{def:rungekuttaorder}, it follows that $\errem\approx{}Kh^{q+1}$,
where $q=\min(p,\widehat{p}\,)$. With $1\approx{}Kh_{\mathrm{opt}}^{q+1}$,
one finds the optimal step size

\begin{equation}
    \label{eq:embeddedoptimalstepsize}
    h_{\mathrm{opt}}=h\cdot\Big(\frac{1}{\errem}\Big)^{\frac{1}{q+1}}.
\end{equation}

If $\errem\leq1$, the solution step is accepted, the time level is increased by
$h$, and the step length is increased. Which of the two approximations $x_{n+1}$
or $\widehat{x}_{n+1}$ are used to continue the integration varies depending on the embedded method in
question. Continuing the integration with the higher order result is commonly
referred to as \emph{local extrapolation}. If $\errem>1$, the solution step is
rejected, the time level remains unaltered, and the step length is decreased.
The  procedure for updating the step length can be summarized as follows:


\begin{equation}
    \label{eq:embeddedstepsizeadjustment}
h_{\mathrm{new}}=\begin{cases}%
    \min(\facem_{\mathrm{max}}\cdot{}h,\facem\cdot{}h_{\mathrm{opt}}),&
\textnormal{if the solution step is accepted}\\
\facem\cdot{}h_{\mathrm{opt}},&\textnormal{if the solution step is rejected}%
\end{cases}
\end{equation}

where $\facem$ and $\facem_{\mathrm{max}}$ are numerical safety factors,
intended to prevent increasing the step size \emph{too} much. For this project,
$\facem=0.8$ and $\facem_{\mathrm{max}}=2.0$ were used throughout.

