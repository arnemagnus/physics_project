{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The numerical integrators are located in a module two levels above\n",
    "# the current working directory. Hence:\n",
    "import sys\n",
    "sys.path.insert(0, '../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing required packages:\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rc('text',usetex=True)\n",
    "%matplotlib inline\n",
    "\n",
    "# Numba (JiT)\n",
    "from numba import jit\n",
    "\n",
    "# (Primitive) timing functionality\n",
    "import time \n",
    "\n",
    "# Multiprocessing:\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Spline interpolation:\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "\n",
    "# Check whether folders exist or not, necessary\n",
    "# for storing advected states:\n",
    "import os\n",
    "import errno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that makes a directory if it does not exist,\n",
    "# and raises an exception otherwise \n",
    "# (necessary for storing advected states)\n",
    "\n",
    "def ensure_path_exists(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exception:\n",
    "        if exception.errno != errno.EEXIST:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Domain of the velocity field:\n",
    "x_min, x_max = 0., 2.\n",
    "y_min, y_max = 0., 1.\n",
    "\n",
    "# Domain lengths in either direction\n",
    "x_len, y_len = x_max - x_min, y_max - y_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the velocity field:\n",
    "\n",
    "@jit(nopython=True)\n",
    "def _doublegyre(t,x,A,e,w):\n",
    "    # a(t)\n",
    "    a = e * np.sin(w*t)       \n",
    "    # b(t)\n",
    "    b = 1 - 2*e*np.sin(w*t)  \n",
    "    # f(x,t)\n",
    "    f = a*x[0,:]**2 + b*x[0,:]\n",
    "    # df/dx\n",
    "    dfdx = 2*a*x[0,:] + b\n",
    "    \n",
    "    v = np.empty(x.shape)                         \n",
    "    # x-component:\n",
    "    v[0,:] = -np.pi*A*np.sin(np.pi*f)*np.cos(np.pi*x[1,:])\n",
    "    # y-component:\n",
    "    v[1,:] = np.pi*A*np.cos(np.pi*f)*np.sin(np.pi*x[1,:])*dfdx\n",
    "    return v \n",
    "\n",
    "@jit(nopython=True)\n",
    "def doublegyre_wrapper(t,x):\n",
    "    # Parameters of the velocity field (Cf. Farazmand & Haller, 2012)\n",
    "    # A\n",
    "    A = 0.1\n",
    "    # epsilon\n",
    "    e = 0.1\n",
    "    # omega\n",
    "    w = 2*np.pi/10\n",
    "    return _doublegyre(t,x,A,e,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function returning a grid of particles meant for plotting etc.\n",
    "def grid_of_particles(Nx,Ny=None):\n",
    "    if Ny is None:\n",
    "        Ny = np.round(Nx*y_len/x_len).astype(int)\n",
    "    \n",
    "    dx = x_len/Nx\n",
    "    dy = y_len/Ny\n",
    "    \n",
    "    x0 = (np.arange(Nx)+1./2.)*dx\n",
    "    y0 = (np.arange(Ny)+1./2.)*dy\n",
    "    \n",
    "    y, x = np.meshgrid(y0,x0)\n",
    "    \n",
    "    return np.array([x,y])\n",
    "\n",
    "# Function returning a flattened grid of particles, meant for\n",
    "# advection, and only supposed to be used by\n",
    "# other functions (i.e., not called directly by the user)\n",
    "def _grid_of_particles_for_transport(grid):\n",
    "    Nx = np.shape(grid)[1]\n",
    "    Ny = np.shape(grid)[2]\n",
    "    \n",
    "    _grid = np.empty((2,Nx*Ny))\n",
    "    \n",
    "    x0 = grid[0][:,0]\n",
    "    y0 = grid[1][0]\n",
    "    \n",
    "    for j in range(Nx):\n",
    "        _grid[0,j*Ny:(j+1)*Ny] = x0[j]\n",
    "        _grid[1,j*Ny:(j+1)*Ny] = y0\n",
    "        \n",
    "    return _grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# String set containing the names of the implemented\n",
    "# fixed stepsize integrators:\n",
    "fixed_stepsize_integrators = set(['euler', 'rk2', 'rk3', 'rk4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions advecting particles with positions defined by meshgrids [X,Y]\n",
    "\n",
    "def endpoints(t_curr,t_end,pos_curr,h,integrator,deriv,n_proc=4,atol=None,rtol=None):\n",
    "    # Flatten input meshgrids for efficiency:\n",
    "    Nx = np.shape(pos_curr)[1]\n",
    "    Ny = np.shape(pos_curr)[2]\n",
    "    pos_curr = _grid_of_particles_for_transport(pos_curr)\n",
    "    partition = np.floor(np.size(pos_curr,1)/n_proc).astype(int)\n",
    "    \n",
    "    queuelist = [mp.Queue() for j in range(n_proc)]\n",
    "    if integrator.__name__ in fixed_stepsize_integrators:\n",
    "        processlist = [mp.Process(target = _endpoints_fixed_slice,\n",
    "                             args=(t_curr,t_end,\n",
    "                                  pos_curr[:,j*partition:np.size(pos_curr,1) if j+1 is n_proc else (j+1)*partition],\n",
    "                                  h,integrator,deriv,queuelist[j])) for j in range(n_proc)]\n",
    "    else:\n",
    "        processlist = [mp.Process(target = _endpoints_fixed_slice,\n",
    "                             args=(t_curr,t_end,\n",
    "                                  pos_curr[:,j*partition:np.size(pos_curr,1) if j+1 is n_proc else (j+1)*partition],\n",
    "                                  h,integrator,deriv,atol,rtol,queuelist[j])) for j in range(n_proc)]\n",
    "    \n",
    "    for process in processlist:\n",
    "        process.start()\n",
    "    for j, queue in enumerate(queuelist):\n",
    "        pos_curr[:,j*partition:np.size(pos_curr,1) if j+1 is n_proc else (j+1)*partition] = queue.get()\n",
    "    for process in processlist:\n",
    "        process.join()\n",
    "        \n",
    "    return pos_curr.reshape((2,Ny,Nx))\n",
    "    \n",
    "def _endpoints_fixed_slice(t_curr,t_end,pos_curr,h,integrator,deriv,q):\n",
    "    t = t_curr\n",
    "    while(t < t_end):\n",
    "        h = np.minimum(h,t_end-t)\n",
    "        t, pos_curr, h = integrator(t,pos_curr,h,deriv)\n",
    "    q.put(pos_curr)\n",
    "    \n",
    "def _endpoints_adaptive_slice(t_curr,t_end,pos_curr,h,integrator,deriv,atol,rtol,q):\n",
    "    h = np.ones(np.size(pos_curr,1))*h\n",
    "    t = np.ones(np.size(pos_curr,1))*t_curr\n",
    "    while(np.any(t < t_end)):\n",
    "        h = np.minimum(h,t_end-t)\n",
    "        t, pos_curr, h = integrator(t,pos_curr,h,deriv,atol,rtol)\n",
    "    q.put(pos_curr)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Check that the advection works (as expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numerical_integrators.singlestep import rk2\n",
    "Nx = 200\n",
    "Ny = 100\n",
    "\n",
    "pos_init = grid_of_particles(Nx,Ny)\n",
    "\n",
    "t_curr = 0.\n",
    "t_max = 20.\n",
    "dt = 0.01\n",
    "\n",
    "pos_end = endpoints(t_curr,t_max,pos_init,h=dt,integrator=rk2,deriv=doublegyre_wrapper)\n",
    "\n",
    "plt.figure(figsize=(12,8),dpi=80)\n",
    "plt.scatter(pos_end[0],pos_end[1],s=2,lw=0)\n",
    "plt.title(r'RK2 advected grid of initial particles, $Nx={}$, $Ny={}$, $\\Delta t={}$, $T={}$'.format(Nx,Ny,dt,t_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Define functions which return eigenvalues and -vectors of strain tensors (i.e., characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that takes the initial time, end time, integration step\n",
    "# and initial positions (meshgrids) as inputs, returning\n",
    "# the computed eigenvalues and eigenvectors of the strain tensors\n",
    "# at the end time\n",
    "def characteristics(t_curr,t_end,pos_curr,h,integrator,rhs,n_proc=4,atol=1.e-6,rtol=1.e-9):\n",
    "    # If the advection has already been performed previously, load saved state\n",
    "    \n",
    "    # For fixed step integrators, the tolerance plays no role, and its value is thus not\n",
    "    # stored in the file names; similarly, the (initial) step length plays no _real_\n",
    "    # role for adaptive step size integrators, and is thus not stored in file names.\n",
    "    \n",
    "    dx = pos_curr[0,1,0]-pos_curr[0,0,0]\n",
    "    dy = pos_curr[1,0,1]-pos_curr[1,0,0]\n",
    "    \n",
    "    deltax = np.minimum(1e-5,dx*1e-2)\n",
    "    deltay = np.minimum(1e-5,dy*1e-2)\n",
    "    \n",
    "    try: \n",
    "        if integrator.__name__ in fixed_stepsize_integrators:\n",
    "            lambda1 = np.load('precomputed_characteristics/{}/lambda1_Nx={}_Ny={}_dx={}_dy={}_deltax={}_deltay={}_t_curr={}_t_end={}_h={}.npy'.format(\n",
    "                                    integrator.__name__,np.shape(pos_curr)[1],np.shape(pos_curr)[2],dx,dy,deltax,deltay,t_curr,t_end,h))\n",
    "            lambda2 = np.load('precomputed_characteristics/{}/lambda2_Nx={}_Ny={}_dx={}_dy={}_deltax={}_deltay={}_t_curr={}_t_end={}_h={}.npy'.format(\n",
    "                                    integrator.__name__,np.shape(pos_curr)[1],np.shape(pos_curr)[2],dx,dy,deltax,deltay,t_curr,t_end,h))\n",
    "            xi1 = np.load('precomputed_characteristics/{}/xi1_Nx={}_Ny={}_dx={}_dy={}_deltax={}_deltay={}_t_curr={}_t_end={}_h={}.npy'.format(\n",
    "                                    integrator.__name__,np.shape(pos_curr)[1],np.shape(pos_curr)[2],dx,dy,deltax,deltay,t_curr,t_end,h))\n",
    "            xi2 = np.load('precomputed_characteristics/{}/xi2_Nx={}_Ny={}_dx={}_dy={}_deltax={}_deltay={}_t_curr={}_t_end={}_h={}.npy'.format(\n",
    "                                    integrator.__name__,np.shape(pos_curr)[1],np.shape(pos_curr)[2],dx,dy,deltax,deltay,t_curr,t_end,h))\n",
    "        else:\n",
    "            lambda1 = np.load('precomputed_characteristics/{}/lambda1_Nx={}_Ny={}_dx={}_dy={}_deltax={}_deltay={}_t_curr={}_t_end={}_atol={}_rtol={}.npy'.format(\n",
    "                                    integrator.__name__,np.shape(pos_curr)[1],np.shape(pos_curr)[2],dx,dy,deltax,deltay,t_curr,t_end,atol,rtol))\n",
    "            lambda2 = np.load('precomputed_characteristics/{}/lambda2_Nx={}_Ny={}_dx={}_dy={}_deltax={}_deltay={}_t_curr={}_t_end={}_atol={}_rtol={}.npy'.format(\n",
    "                                    integrator.__name__,np.shape(pos_curr)[1],np.shape(pos_curr)[2],dx,dy,deltax,deltay,t_curr,t_end,atol.rtol))\n",
    "            xi1 = np.load('precomputed_characteristics/{}/xi1_Nx={}_Ny={}_dx={}_dy={}_deltax={}_deltay={}_t_curr={}_t_end={}_atol={}_rtol={}.npy'.format(\n",
    "                                    integrator.__name__,np.shape(pos_curr)[1],np.shape(pos_curr)[2],dx,dy,deltax,deltay,t_curr,t_end,atol,rtol))\n",
    "            xi2 = np.load('precomputed_characteristics/{}/xi2_Nx={}_Ny={}_dx={}_dy={}_deltax={}_deltay={}_t_curr={}_t_end={}_atol={}_rtol={}.npy'.format(\n",
    "                                    integrator.__name__,np.shape(pos_curr)[1],np.shape(pos_curr)[2],dx,dy,deltax,deltay,t_curr,t_end,atol,rtol))\n",
    "        print('Precomputed characteristics found! Advection not necessary in this case.')\n",
    "    except IOError:\n",
    "        tic = time.time()\n",
    "        print('Precomputed characteristics not found! Please wait!')\n",
    "        lambda1, lambda2, xi1, xi2 = _characteristics(t_curr,t_end,pos_curr,h,integrator,rhs,dx,dy,deltax,deltay,n_proc,atol,rtol)\n",
    "\n",
    "        toc = time.time()\n",
    "        \n",
    "        print('Advection etc. was necessary, time elapsed: {} seconds'.format(toc-tic))\n",
    "        \n",
    "        if integrator.__name__ in fixed_stepsize_integrators:\n",
    "            np.save('precomputed_characteristics/{}/lambda1_Nx={}_Ny={}_dx={}_dy={}_deltax={}_deltay={}_t_curr={}_t_end={}_h={}.npy'.format(\n",
    "                                    integrator.__name__,np.shape(pos_curr)[1],np.shape(pos_curr)[2],dx,dy,deltax,deltay,t_curr,t_end,h), lambda1)\n",
    "            np.save('precomputed_characteristics/{}/lambda2_Nx={}_Ny={}_dx={}_dy={}_deltax={}_deltay={}_t_curr={}_t_end={}_h={}.npy'.format(\n",
    "                                    integrator.__name__,np.shape(pos_curr)[1],np.shape(pos_curr)[2],dx,dy,deltax,deltay,t_curr,t_end,h), lambda2)\n",
    "            np.save('precomputed_characteristics/{}/xi1_Nx={}_Ny={}_dx={}_dy={}_deltax={}_deltay={}_t_curr={}_t_end={}_h={}.npy'.format(\n",
    "                                    integrator.__name__,np.shape(pos_curr)[1],np.shape(pos_curr)[2],dx,dy,deltax,deltay,t_curr,t_end,h), xi1)\n",
    "            np.save('precomputed_characteristics/{}/xi2_Nx={}_Ny={}_dx={}_dy={}_deltax={}_deltay={}_t_curr={}_t_end={}_h={}.npy'.format(\n",
    "                                    integrator.__name__,np.shape(pos_curr)[1],np.shape(pos_curr)[2],dx,dy,deltax,deltay,t_curr,t_end,h), xi2)\n",
    "            \n",
    "        else:\n",
    "            np.save('precomputed_characteristics/{}/lambda1_Nx={}_Ny={}_dx={}_dy={}_deltax={}_deltay={}_t_curr={}_t_end={}_atol={}_rtol={}.npy'.format(\n",
    "                                    integrator.__name__,np.shape(pos_curr)[1],np.shape(pos_curr)[2],dx,dy,deltax,deltay,t_curr,t_end,atol,rtol), lambda1)\n",
    "            np.save('precomputed_characteristics/{}/lambda2_Nx={}_Ny={}_dx={}_dy={}_deltax={}_deltay={}_t_curr={}_t_end={}_atol={}_rtol={}.npy'.format(\n",
    "                                    integrator.__name__,np.shape(pos_curr)[1],np.shape(pos_curr)[2],dx,dy,deltax,deltay,t_curr,t_end,atol,rtol), lambda2)\n",
    "            np.save('precomputed_characteristics/{}/xi1_Nx={}_Ny={}_dx={}_dy={}_deltax={}_deltay={}_t_curr={}_t_end={}_atol={}_rtol={}.npy'.format(\n",
    "                                    integrator.__name__,np.shape(pos_curr)[1],np.shape(pos_curr)[2],dx,dy,deltax,deltay,t_curr,t_end,atol,rtol), xi1)\n",
    "            np.save('precomputed_characteristics/{}/xi2_Nx={}_Ny={}_dx={}_dy={}_deltax={}_deltay={}_t_curr={}_t_end={}_atol={}_rtol={}.npy'.format(\n",
    "                                    integrator.__name__,np.shape(pos_curr)[1],np.shape(pos_curr)[2],dx,dy,deltax,deltay,t_curr,t_end,atol,rtol), xi2)\n",
    "        \n",
    "        print('Characteristics now stored. Advection will not be necessary the next time the same parameters are used!')\n",
    "        \n",
    "    return lambda1, lambda2, xi1, xi2\n",
    "        \n",
    "def _characteristics(t_curr,t_end,pos_curr,h,integrator,rhs,dx,dy,deltax,deltay,n_proc,atol,rtol):\n",
    "    # Advect main and auxiliary grid points:\n",
    "    grid_end = _endpoints_grid(t_curr,t_end,np.array([_grid_of_particles_for_transport(pos_curr),\n",
    "                                                        _grid_of_particles_for_transport(pos_curr)+np.array([deltax,0]).reshape(2,1),\n",
    "                                                        _grid_of_particles_for_transport(pos_curr)+np.array([0,deltay]).reshape(2,1),\n",
    "                                                        _grid_of_particles_for_transport(pos_curr)+np.array([-deltax,0]).reshape(2,1),\n",
    "                                                        _grid_of_particles_for_transport(pos_curr)+np.array([0,-deltay]).reshape(2,1)]),\n",
    "                                h,integrator,rhs,n_proc,atol,rtol)\n",
    "    pos_main = grid_end[0,:,:].reshape(np.shape(pos_curr))\n",
    "    pos_right = grid_end[1,:,:].reshape(np.shape(pos_curr))\n",
    "    pos_top = grid_end[2,:,:].reshape(np.shape(pos_curr))\n",
    "    pos_left = grid_end[3,:,:].reshape(np.shape(pos_curr))\n",
    "    pos_beneath = grid_end[4,:,:].reshape(np.shape(pos_curr))\n",
    "    \n",
    "    main_tensor, auxiliary_tensor = _find_strain_tensors(pos_main,pos_right,pos_top,pos_left,pos_beneath,dx,dy,deltax,deltay)\n",
    "    \n",
    "    lambda1, lambda2, xi1, xi2 = _find_characteristics(main_tensor,auxiliary_tensor)\n",
    "    \n",
    "    return lambda1, lambda2, xi1, xi2\n",
    "\n",
    "def _endpoints_grid(t_curr,t_end,pos_curr,h,integrator,rhs,n_proc,atol,rtol):\n",
    "    partition = np.floor(np.size(pos_curr,2)/n_proc).astype(int)\n",
    "    queuelist = [mp.Queue() for j in range(n_proc)]\n",
    "    if integrator.__name__ in fixed_stepsize_integrators:\n",
    "        processlist = [mp.Process(target=_endpoints_grid_fixed_slice,\n",
    "                                 args=(t_curr,t_end,\n",
    "                                      pos_curr[:,:,j*partition:np.size(pos_curr,2) if j+1 is n_proc else (j+1)*partition],\n",
    "                                      h,integrator,rhs,queuelist[j])) for j in range(n_proc)]\n",
    "    else:\n",
    "        processlist = [mp.Process(target=_endpoints_adaptive_slice,\n",
    "                                 args=(t_curr,t_end,\n",
    "                                      pos_curr[:,:,j*partition:np.size(pos_curr,2) if j+1 is n_proc else (j+1)*partition],\n",
    "                                      h,integrator,rhs,atol,rtol,queuelist[j])) for j in range(n_proc)]\n",
    "        \n",
    "    for process in processlist:\n",
    "        process.start()\n",
    "    for j, queue in enumerate(queuelist):\n",
    "        pos_curr[:,:,j*partition:np.size(pos_curr,2) if j+1 is n_proc else (j+1)*partition] = queue.get()\n",
    "    for process in processlist:\n",
    "        process.join()\n",
    "    \n",
    "    return pos_curr\n",
    "\n",
    "def _endpoints_grid_fixed_slice(t_curr,t_end,pos_curr,h,integrator,rhs,q):\n",
    "    for j in range(5):\n",
    "        stride = np.copy(h)\n",
    "        t = np.copy(t_curr)\n",
    "        while (t<t_end):\n",
    "            stride = np.minimum(stride,t_end-t)\n",
    "            t,pos_curr[j,:,:],stride = integrator(t,pos_curr[j,:,:],stride,rhs)        \n",
    "    q.put(pos_curr)\n",
    "    \n",
    "def _endpoints_grid_adaptive_slice(t_curr,t_end,pos_curr,h,integrator,rhs,atol,rtol,q):\n",
    "    for j in range(5):\n",
    "        stride = np.ones(np.size(pos_curr,2))*h\n",
    "        t = np.ones(np.size(pos_curr,2))*t_curr\n",
    "        while (np.any(t<t_end)):\n",
    "            stride = np.minimum(stride,t_end-t)\n",
    "            t,pos_curr[j,:,:],stride = integrator(t,pos_curr[j,:,:],stride,rhs,atol=atol,rtol=rtol)        \n",
    "    q.put(pos_curr)\n",
    "    \n",
    "def _find_strain_tensors(pos_main,pos_right,pos_above,pos_left,pos_beneath,dx,dy,deltax,deltay):\n",
    "    # Find Jacobian of auxiliary grid:\n",
    "    dF_a = np.empty((2,2,np.size(pos_main,1),np.size(pos_main,2)))\n",
    "    \n",
    "    # Centered differencing throughout:\n",
    "    # dx/dx\n",
    "    dF_a[0,0,:,:] = (pos_right[0]-pos_left[0])/(2*deltax)\n",
    "    # dx/dy\n",
    "    dF_a[0,1,:,:] = (pos_above[0]-pos_beneath[0])/(2*deltay)\n",
    "    # dy/dx\n",
    "    dF_a[1,0,:,:] = (pos_right[1]-pos_left[1])/(2*deltax)\n",
    "    # dy/dy\n",
    "    dF_a[1,1,:,:] = (pos_above[1]-pos_beneath[1])/(2*deltay)\n",
    "    \n",
    "    # Find Jacobian of main grid:\n",
    "    dF = np.empty(np.shape(dF_a))\n",
    "    \n",
    "    # dx/dx\n",
    "    # Centered differences for the interior points:\n",
    "    dF[0,0,1:-1,:] = (pos_main[0,2:,:]-pos_main[0,0:-2,:])/(2*dx)\n",
    "    # Second order accurate forwards / backwards difference for the edges:\n",
    "    dF[0,0,0,:]  = (-3*pos_main[0,0,:]+4*pos_main[0,1,:]-2*pos_main[0,2,:])/(2*dx)\n",
    "    dF[0,0,-1,:] = (3*pos_main[0,-1,:]-4*pos_main[0,-2,:]+2*pos_main[0,-3,:])/(2*dx)\n",
    "    \n",
    "    # dx/dy\n",
    "    # Centered differences for the interior points:\n",
    "    dF[0,1,:,1:-1] = (pos_main[0,:,2:]-pos_main[0,:,0:-2])/(2*dy) \n",
    "    # Second order accurate forwards / backwards difference for the edges:\n",
    "    dF[0,1,:,0]  = (-3*pos_main[0,:,0]+4*pos_main[0,:,1]-2*pos_main[0,:,2])/(2*dy)\n",
    "    dF[0,1,:,-1] = (3*pos_main[0,:,-1]-4*pos_main[0,:,-2]+2*pos_main[0,:,-3])/(2*dy)\n",
    "    \n",
    "    # dy/dx\n",
    "    # Centered differences for the interior points:\n",
    "    dF[1,0,1:-1,:] = (pos_main[1,2:,:]-pos_main[1,0:-2,:])/(2*dx)\n",
    "    # Second order accurate forwards / backwards difference for the edges:\n",
    "    dF[1,0,0,:]  = (-3*pos_main[1,0,:]+4*pos_main[1,1,:]-2*pos_main[1,2,:])/(2*dx) \n",
    "    dF[1,0,-1,:] = (3*pos_main[1,-1,:]-4*pos_main[1,-2,:]+2*pos_main[1,-3,:])/(2*dx)\n",
    "    \n",
    "    # dy/dy\n",
    "    # Centered differences for the interior points:\n",
    "    dF[1,1,:,1:-1] = (pos_main[1,:,2:]-pos_main[1,:,0:-2])/(2*dy)  \n",
    "    # Second order accurate forwards / backwards difference for the edges:\n",
    "    dF[1,1,:,0]  = (-3*pos_main[1,:,0]+4*pos_main[1,:,1]-2*pos_main[1,:,2])/(2*dy)\n",
    "    dF[1,1,:,-1] = (3*pos_main[1,:,-1]-4*pos_main[1,:,-2]+2*pos_main[1,:,-3])/(2*dy)\n",
    "    \n",
    "    # Allocate the strain tensors:\n",
    "    C = np.empty(np.shape(dF))\n",
    "    C_a = np.empty(np.shape(dF_a))\n",
    "    \n",
    "    # Explicitly calculate the strain tensors:\n",
    "    for i in range(dF.shape[2]):\n",
    "        for j in range(dF.shape[3]):\n",
    "            C[:,:,i,j] = np.dot(dF[:,:,i,j].T,dF[:,:,i,j])\n",
    "            C_a[:,:,i,j] = np.dot(dF_a[:,:,i,j].T,dF_a[:,:,i,j])\n",
    "            \n",
    "    return C, C_a\n",
    "\n",
    "def _find_characteristics(main_tensor,auxiliary_tensor):\n",
    "    lambda1 = np.empty((main_tensor.shape[2],main_tensor.shape[3]))\n",
    "    lambda2 = np.empty(lambda1.shape)\n",
    "    xi1 = np.empty((2,lambda1.shape[0],lambda1.shape[1]))\n",
    "    xi2 = np.empty(xi1.shape)\n",
    "    \n",
    "    for i in range(lambda1.shape[0]):\n",
    "        for j in range(lambda1.shape[1]):\n",
    "            values, vectors = np.linalg.eigh(main_tensor[:,:,i,j])\n",
    "            values_a, vectors_a = np.linalg.eigh(auxiliary_tensor[:,:,i,j])\n",
    "            \n",
    "            # Linalg.eigh returns the eigenvalues sorted in ascending order\n",
    "            # wrt magnitude, and similarly for the corresponding eigenvectors\n",
    "            \n",
    "            lambda1[i,j] = values[0]\n",
    "            lambda2[i,j] = values[1]\n",
    "            \n",
    "            xi1[:,i,j] = vectors_a[:,0]\n",
    "            xi2[:,i,j] = vectors_a[:,1]\n",
    "            \n",
    "    return lambda1, lambda2, xi1, xi2\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Define grid cells, time step, simulation time and integrator\n",
    "\n",
    "## Then, calculate the eigenvectors and -values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numerical_integrators.singlestep import rk4\n",
    "\n",
    "integrator = rk4\n",
    "\n",
    "# Create output directory for precomputed characteristics, if it does not already exist:\n",
    "ensure_path_exists('precomputed_characteristics/{}'.format(integrator.__name__))\n",
    "\n",
    "Nx = 1000\n",
    "Ny = 500\n",
    "\n",
    "t_min = 0.\n",
    "t_max = 20.\n",
    "dt = 0.01\n",
    "\n",
    "pos_init = grid_of_particles(Nx,Ny)\n",
    "\n",
    "lambda1, lambda2, xi1, xi2 = characteristics(t_min,t_max,pos_init,dt,integrator,doublegyre_wrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8),dpi=80)\n",
    "plt.pcolormesh(pos_init[0], pos_init[1], np.log(np.abs(lambda2)+1)/(2*np.abs(t_max)))\n",
    "plt.colorbar()\n",
    "plt.title(r'FTLE field, i.e., $\\log(|\\lambda_{2} + 1|) / 2|T|$')\n",
    "plt.xlim(0,2)\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 3: Define functions returning masks for the ICs satisfying (A) and (B):\n",
    "\n",
    "## (A): $\\lambda_{1}(\\mathbf{x}_{0}) \\neq \\lambda_{2}(\\mathbf{x}_{0}) > 1 $\n",
    "## (B): $\\langle \\mathbf{\\xi}_{2}(\\mathbf{x}_{0}), \\nabla^{2} \\lambda_2(\\mathbf{x}_0) \\mathbf{\\xi}_2(\\mathbf{x}_0) \\rangle \\leq 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_true(lambda1, lambda2):\n",
    "    return np.logical_and(lambda1<lambda2,lambda2>1)\n",
    "\n",
    "# When interpreting (B) as the Laplacian of just the eigenvalue:\n",
    "def b_true(lambda2, xi2):\n",
    "    return np.less_equal(np.sum(xi2*_laplacian_eigenvalue(lambda2)*xi2,axis=0),0)\n",
    "\n",
    "def _laplacian_eigenvalue(lambda_):\n",
    "    Nx = np.size(lambda_,0)\n",
    "    Ny = np.size(lambda_,1)\n",
    "    \n",
    "    dx = x_len/Nx\n",
    "    dy = y_len/Ny\n",
    "    \n",
    "    lapl = np.empty((Nx,Ny))\n",
    "    \n",
    "    # First direction:\n",
    "    # Use centered differencing for internal points\n",
    "    lapl[1:-1,:] = (lambda_[2:,:]-2*lambda_[1:-1,:]+lambda_[0:-2,:])/(dx**2)\n",
    "    # Use second order accurate forwards/backwards differencing for domain edges:\n",
    "    lapl[0,:] = (2*lambda_[0,:]-5*lambda_[1,:]+4*lambda_[2,:]-lambda_[3,:])/(dx**2)\n",
    "    lapl[-1,:] = (2*lambda_[-1,:]-5*lambda_[-2,:]+4*lambda_[-3,:]-lambda_[-4,:])/(dx**2)\n",
    "    \n",
    "    # Second direction:\n",
    "    # Use centered differencing for internal points\n",
    "    lapl[:,1:-1] += (lambda_[:,2:]-2*lambda_[:,1:-1]+lambda_[:,0:-2])/(dy**2)\n",
    "    # Use second order accurate forwards/backwards differencing for domain edges:\n",
    "    lapl[:,0] += (2*lambda_[:,0]-5*lambda_[:,1]+4*lambda_[:,2]-lambda_[:,3])/(dy**2)\n",
    "    lapl[:,-1] += (2*lambda_[:,-1]-5*lambda_[:,-2]+4*lambda_[:,-3]-lambda_[:,-4])/(dy**2)\n",
    "    \n",
    "    return lapl\n",
    "\n",
    "# When interpreting (B) as the Laplacian of the eigenvalue-eigenvector product:\n",
    "def b_true2(lambda2,xi2):\n",
    "    return np.less_equal(np.sum(xi2*_laplacian_eigenvalue_eigenvector_product(lambda2,xi2),axis=0),0)\n",
    "\n",
    "def _laplacian_eigenvalue_eigenvector_product(lambda_,xi_):\n",
    "    Nx = np.size(lambda_,0)\n",
    "    Ny = np.size(lambda_,1)\n",
    "    \n",
    "    dx = x_len/Nx\n",
    "    dy = y_len/Ny\n",
    "    \n",
    "    lapl = np.empty((2,Nx,Ny))\n",
    "    \n",
    "    # First direction: Use centered differencing for internal points\n",
    "    lapl[:,1:-1,:] = (lambda_[2:,:]*xi_[:,2:,:]-2*lambda_[1:-1,:]*xi_[:,1:-1,:]+lambda_[0:-2,:]*xi_[:,0:-2,:])/(dx**2)\n",
    "    # Use second order accurate forwards/backwards differencing for domain edges:\n",
    "    lapl[:,0,:] = (2*lambda_[0,:]*xi_[:,0,:]-5*lambda_[1,:]*xi_[:,1,:]+4*lambda_[2,:]*xi_[:,2,:]-lambda_[3,:]*xi_[:,3,:])/(dx**2)\n",
    "    lapl[:,-1,:] = (2*lambda_[-1,:]*xi_[:,-1,:]-5*lambda_[-2,:]*xi_[:,-2,:]+4*lambda_[-3,:]*xi_[:,-3,:]-lambda_[-4,:]*xi_[:,-4,:])/(dx**2)\n",
    "    \n",
    "    # Second direction: Use centered differencing for internal points\n",
    "    lapl[:,:,1:-1] += (lambda_[:,2:]*xi_[:,:,2:]-2*lambda_[:,1:-1]*xi_[:,:,1:-1]+lambda_[:,0:-2]*xi_[:,:,0:-2])/(dy**2)\n",
    "    # Use second order accurate forwards/backwards differencing for domain edges:\n",
    "    lapl[:,:,0] += (2*lambda_[:,0]*xi_[:,:,0]-5*lambda_[:,1]*xi_[:,:,1]+4*lambda_[:,2]*xi_[:,:,2]-lambda_[:,3]*xi_[:,:,3])/(dy**2)\n",
    "    lapl[:,:,-1] += (2*lambda_[:,-1]*xi_[:,:,-1]-5*lambda_[:,-2]*xi_[:,:,-2]+4*lambda_[:,-3]*xi_[:,:,-3]-lambda_[:,-4]*xi_[:,:,-4])/(dy**2)\n",
    "    \n",
    "    return lapl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Find the domains for which conditions (A) and (B) hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_a = a_true(lambda1,lambda2)\n",
    "mask_b = b_true(lambda2,xi2)\n",
    "plt.figure(figsize=(12,8),dpi=80)\n",
    "plt.scatter(pos_init[0,np.logical_and(mask_a,mask_b)],pos_init[1,np.logical_and(mask_a,mask_b)],s=2,c='k')\n",
    "plt.title(r'The domain $\\mathcal{U}_{0}$, i.e. ICs for which (A) and (B) hold (Laplacian of \\emph{eigenvalue} in (B))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_a = a_true(lambda1,lambda2)\n",
    "mask_b2 = b_true2(lambda2,xi2)\n",
    "plt.figure(figsize=(12,8),dpi=80)\n",
    "plt.scatter(pos_init[0,np.logical_and(mask_a,mask_b2)],pos_init[1,np.logical_and(mask_a,mask_b2)],s=2,c='k')\n",
    "plt.title(r'The domain $\\mathcal{U}_{0}$, i.e. ICs for which (A) and (B) hold (Laplacian of \\emph{eigenvalue-eigenvector-product} in (B))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Define functions to choose $\\mathcal{G}_{0}$ as the intersection             between $\\mathcal{U}_{0}$ and a set of vertical and horizontal lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_g0(pos_init,num_horz_lines,num_vert_lines):\n",
    "    Nx = np.size(pos_init,1)\n",
    "    Ny = np.size(pos_init,2)\n",
    "    \n",
    "    mask = np.zeros((Nx,Ny),dtype=np.bool)\n",
    "    \n",
    "    stride_horz = np.floor(Ny/(num_vert_lines+1)).astype(int)\n",
    "    stride_vert = np.floor(Nx/(num_horz_lines+1)).astype(int)\n",
    "    \n",
    "    for j in range(1,num_vert_lines+1):\n",
    "        mask[:,np.minimum(j*stride_horz,Ny-1)] = True\n",
    "    \n",
    "    for j in range(1,num_horz_lines+1):\n",
    "        mask[np.minimum(j*stride_vert,Nx-1),:] = True\n",
    "        \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Choose $\\mathcal{G}_{0}$ by setting the number of vertical and horizontal lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_horz_lines = 4\n",
    "num_vert_lines = 4\n",
    "mask_g0 = find_g0(pos_init,num_horz_lines,num_vert_lines)\n",
    "\n",
    "g0 = pos_init[:,np.logical_and(np.logical_and(mask_a,mask_b),mask_g0)]\n",
    "\n",
    "plt.figure(figsize=(12,8),dpi=80)\n",
    "plt.scatter(g0[0],g0[1],s=2,c='k')\n",
    "plt.title(r'$\\mathcal{G}_{0}$, the intersection between $\\mathcal{U}_{0}$, %i vertical and %i horizontal lines' %(num_vert_lines,num_horz_lines) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Define necessary functions and classes to advect the points in $\\mathcal{G}_{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InABDomain:\n",
    "    def __init__(self,pos_init,mask_a,mask_b,thresh=0.5):\n",
    "        self.inAB_domain_spline = RectBivariateSpline(pos_init[1,0,:],pos_init[0,:,0],np.logical_and(mask_a,mask_b).T)\n",
    "        self.thresh = thresh\n",
    "        \n",
    "    def __call__(self,pos):\n",
    "        return self.inAB_domain_spline.ev(pos[1],pos[0]) > self.thresh\n",
    "    \n",
    "class InNumericalDomain:\n",
    "    def __init__(self,x_min,x_max,y_min,y_max,padding_factor=0.):\n",
    "        self._x_min = x_min-(x_max-x_min)*padding_factor\n",
    "        self._x_max = x_max+(x_max-x_min)*padding_factor\n",
    "        self._y_min = y_min-(y_max-y_min)*padding_factor\n",
    "        self._y_max = y_max+(y_max-y_min)*padding_factor\n",
    "    \n",
    "    def __call__(self,pos):\n",
    "        return pos[0] >= self._x_min and pos[0] <= self._x_max and pos[1] >= self._y_min and pos[1] <= self._y_max\n",
    "    \n",
    "class RescaledSplinedDerivative:\n",
    "    def __init__(self,pos_init,lambda1,lambda2,xi1,x_min,x_max,y_min,y_max,padding_factor=0.):\n",
    "        self._lambda1_spline = RectBivariateSpline(pos_init[1,0,:],pos_init[0,:,0],lambda1.T,bbox=[y_min-(y_max-y_min)*padding_factor,y_max+(y_max-y_min)*padding_factor,x_min-(x_max-x_min)*padding_factor,x_max+(x_max-x_min)*padding_factor])\n",
    "        self._lambda2_spline = RectBivariateSpline(pos_init[1,0,:],pos_init[0,:,0],lambda2.T,bbox=[y_min-(y_max-y_min)*padding_factor,y_max+(y_max-y_min)*padding_factor,x_min-(x_max-x_min)*padding_factor,x_max+(x_max-x_min)*padding_factor])\n",
    "        self._xi1_x_spline = RectBivariateSpline(pos_init[1,0,:],pos_init[0,:,0],xi1[0].T,bbox=[y_min-(y_max-y_min)*padding_factor,y_max+(y_max-y_min)*padding_factor,x_min-(x_max-x_min)*padding_factor,x_max+(x_max-x_min)*padding_factor])\n",
    "        self._xi1_y_spline = RectBivariateSpline(pos_init[1,0,:],pos_init[0,:,0],xi1[1].T,bbox=[y_min-(y_max-y_min)*padding_factor,y_max+(y_max-y_min)*padding_factor,x_min-(x_max-x_min)*padding_factor,x_max+(x_max-x_min)*padding_factor])\n",
    "        self._prev = None\n",
    "        \n",
    "    def set_previous(self,prev):\n",
    "        self._prev = prev\n",
    "        \n",
    "    def _alpha(self,t,pos):\n",
    "        lambda1 = self._lambda1_spline.ev(pos[1],pos[0])\n",
    "        lambda2 = self._lambda2_spline.ev(pos[1],pos[0])\n",
    "        \n",
    "        return ((lambda1-lambda2)/(lambda1+lambda2))**2\n",
    "    \n",
    "    def _normalize(self,xi1_x,xi1_y):\n",
    "        norm = np.sqrt(xi1_x**2+xi1_y**2)\n",
    "        return xi1_x/norm, xi1_y/norm\n",
    "        \n",
    "    def __call__(self,t,pos):\n",
    "        lambda1 = self._lambda1_spline.ev(pos[1],pos[0])\n",
    "        lambda2 = self._lambda2_spline.ev(pos[1],pos[0])\n",
    "        alpha = self._alpha(t,pos)\n",
    "        xi1_x = self._xi1_x_spline.ev(pos[1],pos[0])\n",
    "        xi1_y = self._xi1_y_spline.ev(pos[1],pos[0])\n",
    "        \n",
    "        xi1_x, xi1_y = self._normalize(xi1_x,xi1_y)\n",
    "        \n",
    "        new = alpha*np.array([xi1_x,xi1_y])\n",
    "        \n",
    "        if self._prev is None:\n",
    "            sign = 1\n",
    "        else:\n",
    "            sign = np.sign(np.dot(self._prev,new))\n",
    "        \n",
    "        return sign*new\n",
    "    \n",
    "        \n",
    "    \n",
    "class Strainline:\n",
    "    def __init__(self,startpoint,num_max_points,pos_init,lambda1,lambda2,l_min,l_f_max,x_min,x_max,y_min,y_max,padding_factor=0.):\n",
    "        self._num_max_points = num_max_points\n",
    "        self._pos = np.empty((2,self._num_max_points))\n",
    "        self._pos[:,0] = startpoint\n",
    "        self._lambda1_spline = RectBivariateSpline(pos_init[1,0,:],pos_init[0,:,0],lambda1.T,bbox=[y_min-(y_max-y_min)*padding_factor,y_max+(y_max-y_min)*padding_factor,x_min-(x_max-x_min)*padding_factor,x_max+(x_max-x_min)*padding_factor])\n",
    "        self._lambda2_spline = RectBivariateSpline(pos_init[1,0,:],pos_init[0,:,0],lambda2.T,bbox=[y_min-(y_max-y_min)*padding_factor,y_max+(y_max-y_min)*padding_factor,x_min-(x_max-x_min)*padding_factor,x_max+(x_max-x_min)*padding_factor])\n",
    "        self._length = 0.\n",
    "        self._minimum_length = l_min\n",
    "        self._sufficient_length = False\n",
    "        self._maximum_continious_failure_length = l_f_max\n",
    "        self._continious_failure_length = 0.\n",
    "        self._continious_failure = False\n",
    "        self._stationary_endpoint = False\n",
    "        self._num_points = 1\n",
    "    \n",
    "    def current_alpha(self):\n",
    "        lambda1 = self._lambda1_spline.ev(self._pos[1,self._num_points-1], self._pos[0,self._num_points-1])\n",
    "        lambda2 = self._lambda2_spline.ev(self._pos[1,self._num_points-1], self._pos[0,self._num_points-1])\n",
    "        return ((lambda1-lambda2)/(lambda1+lambda2))**2\n",
    "    \n",
    "    def current_position(self):\n",
    "        return self._pos[:,self._num_points-1]\n",
    "    \n",
    "    def long_enough(self):\n",
    "        return self._sufficient_length\n",
    "    \n",
    "    def is_long_enough(self):\n",
    "        self._sufficient_length = True\n",
    "    \n",
    "    def has_failed_continiously(self):\n",
    "        return self._continious_failure\n",
    "    \n",
    "    def failed_continiously(self):\n",
    "        self._continious_failure = True\n",
    "    \n",
    "    def set_continious_failure_length(self,length):\n",
    "        self._continious_failure_length = length\n",
    "    \n",
    "    def reached_stationary_point(self):\n",
    "        return self._stationary_endpoint\n",
    "    \n",
    "    def get_length(self):\n",
    "        return self._length\n",
    "    \n",
    "    def get_continious_failure_length(self):\n",
    "        return self._continious_failure_length\n",
    "    \n",
    "    def get_num_points(self):\n",
    "        return self._num_points\n",
    "    \n",
    "    def set_length(self,length):\n",
    "        self._length = length\n",
    "        \n",
    "    def append(self,pos):\n",
    "        self._pos[:,self._num_points] = pos\n",
    "        self._num_points += 1\n",
    "        \n",
    "    def average_lambda2(self):\n",
    "        return np.mean(self._lambda2_spline.ev(self._pos[1,:self._num_points],self._pos[0,:self._num_points]))\n",
    "    \n",
    "    def entire_trajectory(self):\n",
    "        return self._pos[:,:self._num_points]\n",
    "    \n",
    "    def _merge(self,other):\n",
    "        pos_left = self.entire_trajectory()\n",
    "        pos_right = other.entire_trajectory()\n",
    "        self._pos = np.empty((2,self._num_max_points+other._num_max_points))\n",
    "        self._pos[:,:self._num_points] = pos_left[:,::-1]\n",
    "        self._pos[:,self._num_points:self._num_points+other._num_points-1] = pos_right[:,1:]\n",
    "        self._num_points = self._num_points + other._num_points - 1\n",
    "        self._length = self._length + other._length\n",
    "        self._sufficient_length = self._length > self._minimum_length\n",
    "        self._continious_failure = self._continious_failure or other._continious_failure\n",
    "        self._stationary_endpoint = self._stationary_endpoint or other._stationary_endpoint\n",
    "    \n",
    "    \n",
    "def advect_strainlines_in_parallel(pos_g0,max_iter,integrator,stride,l_f_max,l_min,tol_alpha,pos_init,lambda1,lambda2,xi1,x_min,x_max,y_min,y_max,padding_factor=0.,n_proc=4):\n",
    "    in_AB_domain = InABDomain(pos_init,a_true(lambda1,lambda2),b_true(lambda1,lambda2))\n",
    "    in_numerical_domain = InNumericalDomain(x_min,x_max,y_min,y_max,padding_factor)\n",
    "    \n",
    "    rhs = RescaledSplinedDerivative(pos_init,lambda1,lambda2,xi1,x_min,x_max,y_min,y_max,padding_factor)\n",
    "    \n",
    "    # First, we integrate forwards\n",
    "    # Container for all strainlines\n",
    "    strainlines_forwards = [Strainline(pos_g0[:,j],max_iter,pos_init,lambda1,lambda2,l_min,l_f_max,x_min,x_max,y_min,y_max,padding_factor) for j in range(np.size(pos_g0,1))]\n",
    "    \n",
    "    # Partition distributed to each process:\n",
    "    partition = np.floor(np.size(pos_g0,1)/n_proc).astype(int)\n",
    "    \n",
    "    queuelist = [mp.Queue() for j in range(n_proc)]\n",
    "    processlist = [mp.Process(target=_advect_strainline_slice,\n",
    "                             args=(strainlines_forwards[j*partition:np.size(strainlines_forwards,0) if j+1 is n_proc else (j+1)*partition],\n",
    "                                   max_iter,rhs,integrator,stride,l_f_max,l_min,tol_alpha,in_AB_domain,\n",
    "                                   in_numerical_domain,j,queuelist[j])) for j in range(n_proc)]\n",
    "    for process in processlist:\n",
    "        process.start()\n",
    "    for j, queue in enumerate(queuelist):\n",
    "        strainlines_forwards[j*partition:np.size(strainlines_forwards,0) if j+1 is n_proc else (j+1)*partition] = queue.get()\n",
    "    for process in processlist:\n",
    "        process.join()\n",
    "        \n",
    "    print('Forwards integration finished. Now integrating backwards:')\n",
    "        \n",
    "    # The, we integrate backwards:\n",
    "    # Container for all strainlines\n",
    "    strainlines_backwards = [Strainline(pos_g0[:,j],max_iter,pos_init,lambda1,lambda2,l_min,l_f_max,x_min,x_max,y_min,y_max,padding_factor) for j in range(np.size(pos_g0,1))]\n",
    "\n",
    "    queuelist = [mp.Queue() for j in range(n_proc)]\n",
    "    # Important: Integrate with NEGATIVE stride\n",
    "    processlist = [mp.Process(target=_advect_strainline_slice,\n",
    "                             args=(strainlines_forwards[j*partition:np.size(strainlines_backwards,0) if j+1 is n_proc else (j+1)*partition],\n",
    "                                   max_iter,rhs,integrator,-stride,l_f_max,l_min,tol_alpha,in_AB_domain,\n",
    "                                   in_numerical_domain,j,queuelist[j])) for j in range(n_proc)]\n",
    "    for process in processlist:\n",
    "        process.start()\n",
    "    for j, queue in enumerate(queuelist):\n",
    "        strainlines_backwards[j*partition:np.size(strainlines_backwards,0) if j+1 is n_proc else (j+1)*partition] = queue.get()\n",
    "    for process in processlist:\n",
    "        process.join()\n",
    "    \n",
    "    strainlines = _merge_forwards_and_backwards_parts(strainlines_backwards,strainlines_forwards)\n",
    "    \n",
    "    print('Backwards integration also finished. Results concatenated.')\n",
    "    \n",
    "    \n",
    "    return strainlines\n",
    "\n",
    "def _advect_strainline_slice(strainlines,max_iter,rhs,integrator,stride,l_f_max,l_min,tol_alpha,in_AB,in_domain,pn,q):\n",
    "    for count, strainline in enumerate(strainlines):\n",
    "        rhs.set_previous(None)\n",
    "        t = 0.\n",
    "        iteration = 0\n",
    "        L = 0.\n",
    "        L_f = 0.\n",
    "        rhs.set_previous(rhs(t,strainline.current_position()))\n",
    "        prev_rhs = rhs(t,strainline.current_position())\n",
    "        t_trial,pos_trial,stride = integrator(t,strainline.current_position(),stride,rhs)\n",
    "        iteration+=1\n",
    "        #print(pos_trial)\n",
    "        #print(in_domain(pos_trial))\n",
    "        while iteration<max_iter and in_domain(pos_trial) and strainline.current_alpha() > tol_alpha and not strainline.has_failed_continiously():\n",
    "            if t_trial is not t:\n",
    "                L += np.sqrt((pos_trial[0]-strainline.current_position()[0])**2+(pos_trial[1]-strainline.current_position()[1])**2)\n",
    "                if not in_AB(pos_trial):\n",
    "                    L_f += np.sqrt((pos_trial[0]-strainline.current_position()[0])**2+(pos_trial[1]-strainline.current_position()[1])**2)\n",
    "                else:\n",
    "                    L_f = 0.\n",
    "                rhs.set_previous(prev_rhs)\n",
    "                t = t_trial\n",
    "                strainline.append(pos_trial)\n",
    "                if L_f > l_f_max:\n",
    "                    strainline.failed_continiously()\n",
    "                    strainline.set_continious_failure_length(L_f)\n",
    "                iteration+=1\n",
    "            prev_rhs = rhs(t,strainline.current_position())\n",
    "            t_trial,pos_trial,stride = integrator(t,strainline.current_position(),stride,rhs)\n",
    "        if L > l_min:\n",
    "            strainline.set_length(L)\n",
    "            strainline.is_long_enough()\n",
    "        if strainline.current_alpha() <= tol_alpha:\n",
    "            strainline.reached_stationary_point()\n",
    "        if not (np.mod(count +  1 +  np.floor(np.size(strainlines,0)/4).astype(int), np.floor(np.size(strainlines,0)/4).astype(int))):\n",
    "            print('Process {}: Finished integrating strainline candidate {} of {}'.format(pn,count+1,np.size(strainlines,0)))\n",
    "    q.put(strainlines)\n",
    "\n",
    "def _merge_forwards_and_backwards_parts(strainlines_backwards,strainlines_forwards):\n",
    "    print(len(strainlines_backwards))\n",
    "    print(len(strainlines_forwards))\n",
    "    #assert len(strainlines_backwards) is len(strainlines_forwards)\n",
    "    for j in range(len(strainlines_backwards)):\n",
    "        strainlines_backwards[j]._merge(strainlines_forwards[j])\n",
    "    #strainlines_backwards._merge(strainlines_forwards)\n",
    "    return strainlines_backwards\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Advect the points in $\\mathcal{G}_{0}$ in the (stationary) $\\vec{\\xi}_{1}$ field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 20000\n",
    "stride = 0.005\n",
    "l_f_max = 0.2\n",
    "l_min = 1\n",
    "tol_alpha = 1.e-6\n",
    "\n",
    "tic = time.time()\n",
    "strainlines = advect_strainlines_in_parallel(g0,max_iter,integrator,stride,l_f_max,l_min,tol_alpha,pos_init,lambda1,lambda2,xi1,x_min,x_max,y_min,y_max)\n",
    "toc = time.time()\n",
    "\n",
    "print('Elapsed time: {} seconds'.format(toc-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8),dpi=80)\n",
    "plt.scatter(pos_init[0,np.logical_and(mask_a,mask_b)], pos_init[1,np.logical_and(mask_a,mask_b)],c='r')\n",
    "for strainline in strainlines:\n",
    "    if strainline.long_enough() and not strainline.has_failed_continiously():\n",
    "        plt.scatter(strainline.entire_trajectory()[0],strainline.entire_trajectory()[1],s=2,c='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8),dpi=80)\n",
    "plt.scatter(g0[0],g0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = strainlines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.copy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = np.copy(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0].long_enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert 1 is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strainlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strainlines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strainlines[1].entire_trajectory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kan ikke allokere nok minne til Ã¥ lagre potensielt alle posisjoner. Bedre med lenket (python-)liste og konvertering til np.array for plotting osv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
